{
    "learning_rate": 4.639040244624586e-05,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 2,
    "lora_r": 4,
    "lora_alpha": 16,
    "lora_dropout": 0.04344164997662244
}